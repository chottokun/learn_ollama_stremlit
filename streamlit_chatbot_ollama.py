import streamlit as st
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_models import ChatOllama
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain.callbacks.base import BaseCallbackHandler

# callback
class StreamHandler(BaseCallbackHandler):
    
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs):
        self.text += token
        self.container.markdown(self.text)

# history
msgs = StreamlitChatMessageHistory(key="history")

# prompt
from langchain.prompts.chat import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

template = """
ã‚ãªãŸã¯å„ªç§€ãªè©±ç›¸æ‰‹ã§ã™ã€‚
"""

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚è‹±èªã§è€ƒãˆæ—¥æœ¬èªã§å›ç­”ã—ã¾ã™ã€‚"),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{question}"),
    ]
)

# Ollamaã‚’åˆæœŸåŒ–
llm = ChatOllama(
    model="ryota39-Phi-3-mini-4k-instruct-dpo-Q4_0.gguf",
)

# Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UI
st.title("ğŸ’¬ Chatbot")
st.caption("ğŸš€ A streamlit chatbot")

# Chain
chain = prompt | llm

chain_with_history = RunnableWithMessageHistory(
    chain,
    lambda session_id: msgs,  # Always return the instance created earlier
    input_messages_key="question",
    history_messages_key="history",
)

for msg in msgs.messages:
    st.chat_message(msg.type).write(msg.content)

if prompt := st.chat_input():

    st.chat_message("human").write(prompt)
    st_callback = StreamHandler(st.empty())
    # sessin_id and callbacks
    config = {"configurable": {"session_id": "any"},
              "callbacks": [st_callback]
              }
    # generate response.
    response = chain_with_history.invoke({"question": prompt}, config)
    st.chat_message("ai").write(response.content)
